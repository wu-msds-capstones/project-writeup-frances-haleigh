[
  {
    "objectID": "capstone.html",
    "href": "capstone.html",
    "title": "Preventative Care in the United States",
    "section": "",
    "text": "To answer questions regarding the effectiveness of preventative care, we investigated current relationships between health care, access to care, insurance type, and overall health outcomes across the United States. To do so, we took a multi-layered approach to our data:\n\nCompare how access to care impacts common health metrics such as life expectancy, mortality, and infant mortality.³\nInvestigate predictability of chronic condition prevalence between public and private insurances.\nEngineer a variable that encapsulates all health metrics to discover what factors are most important to health overall.\n\nBy examining these questions, we aimed to contribute to the understanding of how preventative care can improve public health in the United States."
  },
  {
    "objectID": "capstone.html#data-ingestion",
    "href": "capstone.html#data-ingestion",
    "title": "Preventative Care in the United States",
    "section": "3.1 Data Ingestion",
    "text": "3.1 Data Ingestion\nWe gathered data from two sources: KFF (an independent source for health policy research, polling, and news)⁷ and County Health Rankings and Roadmaps (CHRR).² Though we collected data across several years, we analyzed only data from 2022 due to data quality concerns when comparing year to year.\n\n3.1.1 KFF: Collection and Cleaning\nWe generated a custom report from data available on KFF, downloading a large variety of data from 2017-2022 (not including 2020 due to lack of data collection) for each state in the U.S. Variables we investigated from this dataset included percentage of population on Medicare, percentage of adults who smoke, healthcare expenditure, median annual household income, cervical cancer incidence rate, and many more potentially relevant factors.⁷\nKFF data for each state was downloaded as CSVs. We chose the most recent dates for all of the different health and insurance related questions between 2017-2022. The CSVs originally had a question, state, and value field. We used text parsing to create a column called demographic and a column called group. This allowed us to parse out demographics like age, race/ethnicity, poverty level and create groups within each of those.\nWe also created fields called year and measure, and parsed out the years and measurements from the question field. Some questions had multiple demographics, so we created a secondary_demographic field and a secondary_group field. These are not ranked.\nFinally, we added a county column (which we filled with all NA) and edited the state and question fields to replicate the way that data from our CHFF dataset was formatted. This allowed us to merge the two datasets.\n\n\n3.1.2 CHRR: Collection and Cleaning\nSimilar to KFF, we downloaded data for each state from 2017-2022 (not including 2020 due to lack of data collection) from County Health Rankings and Roadmaps (CHRR). We chose the “20xx County Health Release National Data” links for each year. Data from CHRR originally came in two separate CSVs for each year and broke up the data by each county in the United States. This data included metrics such as life_expectancy, age-adjusted_death_rate, years_of_potential_life_loss_rate, food_environment_index, percentage_of_physically_inactive_adults, percentage_of_excessive_drinking, Primary_Care_Provider_ratio, and much more.²\nFirst, we cleaned up the columns. We reviewed the documentation and renamed any potentially confusing column names. For example, #_Medicaid_Enrollees became no_female_medicaid_enrollees to avoid mistakenly believing the first column included both genders in its count. We dropped columns that would not be of help to us, such as columns containing the word Unreliable. We replaced all spaces with an underscore.\nSecond, we joined the two CSVs for each year to have one CSV per year and added a Year column to help with merging later.\nFinally, we reformatted the CSVs to match that of the KFF data, where our original columns became the question column and the values filled in a new values column. Again, we used text parsing such as grepl and gsub to fill in our newly created demographic, measure, group, secondary_demographic, and secondary_group, columns. For example, if our question was mean_%_Children_in_Poverty_(white), our demographic, group, secondary_demographic, and secondary_group columns became “Race/Ethnicity”, “White”, “Age”, and “0-17”, respectively.\nSince the questions and potential answers collected by CHRR data varied each year, we made sure that our cleaning code was modified for each year to both accommodate the changes in the data and match identical answers from previous years. As an example, the only races that were listed as options in the 2017 data were “White”, “Black”, “Hispanic”, and “Asian”. However, by the 2022 data collection, the options had expanded to include “American Indian/Alaskan Native”, “Native Hawaiian/Other Pacific Islander”, and “Other/Multiple Races.” In 2022, “Black” was changed to “African American,” so we changed it back to “Black” to both match the earlier CHRR data and the KFF data."
  },
  {
    "objectID": "capstone.html#data-organization",
    "href": "capstone.html#data-organization",
    "title": "Preventative Care in the United States",
    "section": "3.2 Data Organization",
    "text": "3.2 Data Organization\nData was combined and normalized to third normal form. The ids were primary keys for each table except for question_responses, where state_id, year_id, and question_id were used as a compound primary key. We used the same foreign key for group and secondary_group and another separate foreign key for both type and secondary_type. All columns had a NOT NULL constraint except for unit_type from the unit table, and unit_id, secondary_group_id, and secondary_type_id from question_responses.\n\n\n\nFigure 1: ERD."
  },
  {
    "objectID": "capstone.html#data-analysis",
    "href": "capstone.html#data-analysis",
    "title": "Preventative Care in the United States",
    "section": "4.1 Data Analysis",
    "text": "4.1 Data Analysis\n\n4.1.1 Statistical Thinking\nWe determined health status using commonly used proxies such as life expectancy and mortality rates.³ We used statistics (log rank tests) and modeling (Kaplan-Meier curves and linear regression) to determine how access to preventative care correlates with health status. We compared proportions across states to account for differences in population.\nIn our linear models created in R, we first took the natural logarithm of income-related data due to both its skewed distribution and disproportionate scale (in comparison to the rest of our data).\n\n\n\n\n\n\nWhat are these statistical tests?\n\n\n\n\n\n\n\n\n\n\n\n\nTest\nDescription\n\n\n\n\nKaplan-Meier Curve\nA Kaplan-Meier (KM) curve is a display of survival data over time and across groups.\n\n\nLog Rank Test\nA log rank test is used to determine if the groups in a KM curve are significant.\n\n\nLinear Regression\nLinear regression is a statistical test used to find and quanitfy linear trends between data.\n\n\n\n\n\n\n\n\n4.1.2 Data Visualization\nWe used data visualization as part of both our exploratory data analysis and in our final outcome. We created maps of the United States to determine if there is a spatial relationship between our variables and quality of health. Various other visualizations were displayed from our statistical analysis and machine learning product, such as Kaplan-Meier curves, graphs of K-Best’s top features, confusion matrices, and K-Means and/or Gaussian Mixture Model scatterplots, where appropriate.\n\n\n4.1.3 Data Engineering\nWe stored our data into a relational database and accessed it with Postgresql (through Railway). We accessed our data in both R and Python using the RPostgreSQL and sqlalchemy libraries, respectively. A detailed description for how this was done is in the data section above.\n\n\n4.1.4 Machine Learning\nWe used machine learning models such as ensembles, logistic regression, random forest, naive bayes, PCA, KMeans, Gaussian Mixture Models, and more to explore relationships and predict health outcomes from our data. For example, we predicted metrics like life expectancy based on our access to care variables. We also predicted the prevalence of common chronic conditions, such as Diabetes, within each state based on the percentage of people on Medicaid. Finally, we created a new variable that represented overall health quality.\n\n4.1.4.1 Process outlines:\n\nGoal 1Goal 2Goal 3\n\n\nPredicting health by access to care\n\nUse KMeans to find the top 10 features from each model. Combine these variables with significant variables from the linear regression models completed in R.\nCreate our desired dataframe by reading in data from our remote database and joining where necessary.\nPreprocess:\n\nDrop NAs while optimizing data frame size via trial and error.\nUse StandardScaler and OneHotEncoder tools from sklearn to transform our numeric and categorical data, respectively.\n\nUse KMeans to find the top 10 features from each model. (See Supplemental Figures 1A, 1B, and 1C). Combine these variables with significant variables from the linear regression models completed in R.\nContinue preprocessing with the reduced dataset (using only variables from step 3)\n\nBin and modify data as necessary. This ensured equal representation across classes for each predicted y variable. A. In order to use classification tools such as RandomForestClassifier or GradientBoostingClassifier, we binned all our data by quartiles before running it through our models. B. For life expectancy, we dropped outliers first (ages below 60 and above 90, see Supplemental Figure 1D).\nTrain/test split dataset\n\nCreate model\n\nUse LogisticRegression, RandomForestClassifier, GradientBoostingClassifier, CategoricalNaiveBayes, and Ensemble. Find which model performs the best.\nHyperparameterize the model that works best from step 5i.\nCross validate finalized model\nTest on testing data to find true accuracy\nConfusion matrix to see what went wrong (see Supplemental Figures 1E and 1F).\n\nAdd PCA to the model\n\nDetermine how many components explain 90% variance in the model (see Supplemental Figures 1G, 1H, and 1I).\nAdd PCA with that number of components to the optimized pipeline made from Step 5.\n\n\n\n\nPredicting disease prevalence by insurance type\n\nManipulate data to find mean prevalence of the disease by state. Use this state-wide data rather than the county data as the Medicaid covariates were only available by state.\nPreprocess, split, and model the data as outlined in the first process.\n\n\n\nEngineering overall health variable\n\nGather our entire dataset (not just access to care related variables) See Section 8.1.1 for a list of all variables used.\nPreprocess the dataset using StandardScaler and OneHotEncoder to the appropriate columns.\nUse PCA to see how much variance can be explained by the first eigenvalue (see Supplemental Figure 1J).\nProject desired health variables to the first eigenvalue.\nCompare weights of all variables to see how much they each contribute to this “new variable.”\n\n\n\n\n\n\n\n\n\n\nWhat are these models and tools?\n\n\n\n\n\n\n4.1.5 Model Optimization Tools\n\n\n\n\n\n\n\nName\nExplaination\n\n\n\n\nK-Best Feature Selection\nK-Best feature selection is a tool used in machine learning used to find which variables in a given model most contribute to its prediction accuracy.\n\n\nConfusion Matrices\nConfusion matrices are plots of the true and predicted values of a given model and are used to determine where a model is succeeding and/or failing.\n\n\n\n\n\n4.1.6 Data Preprocessing Tools\n\n\n\n\n\n\n\nName\nExplaination\n\n\n\n\nStandard Scaler\nStandard Scaler is a tool you can use in machine learning to standardize all numeric inputs so the model can correctly assess the impact of each value.\n\n\nOne Hot Encoder\nSimilar to Standard Scaler, One Hot Encoder is a method use to convert character data to numeric in a standardized way so the model can weigh the impact of character input along with numeric.\n\n\n\n\n\n4.1.7 Supervised Classification Models\n\n\n\n\n\n\n\nName\nExplaination\n\n\n\n\nRandom Forests\nRandom Forests randomly distribute the data given to it into multiple “trees” and averages the outcome from each tree to come to its final result.\n\n\nNaive Bayes\nNaive Bayes uses probability to find the most likely outcome.\n\n\nLogistic Regression\nLogisitic regression finds the linear regression of the log odds of the predictor variables to predict a binary outcome.\n\n\nGradient Boosting\nRather than creating lots of uncorrelated models like Random Forest, Gradient Boosting fits many models where each successive one corrects upon where the previous one was wrong.\n\n\nEnsemble\nEnsemble models combine many user-specified models and comes to its final outcome by averaging the individual outcomes of each model made up within it.\n\n\n\n\n\n4.1.8 Unsupervised Dimension Reduction Model\n\n\n\n\n\n\n\nName\nExplaination\n\n\n\n\nPCA\nPrinciple Component Analysis (PCA) is a method of reducing the number of variables in a model by combining them into the principle components that describe the most variance in a given dataset.\n\n\n\n\n\n4.1.9 Unsupervised Clustering Models\n\n\n\n\n\n\n\nName\nExplaination\n\n\n\n\nK-Means\nK-Means is a clustering method that attempts to divide up the data into a specified number of groups based on how close each data point is to each other.\n\n\nGaussian Mixture Model\nGaussian Mixture Model is another clustering method that assumes a specificed number of normally distributed clusters and assigns data points to the normal curve they best fit.\n\n\n\n\n\n\n\n\n\n\n4.1.10 Data Ethics\nWe were wary of furthering the gap between classes, races, and/or genders. Often, those in lower socioeconomic status tend to have lower quality of health and less access to affordable healthcare. Our goal was not to perpetuate this gap but to find potential solutions for these underserved populations. We also recognized that our datasets were incomplete and that we were not be able to represent everyone’s needs. Those who are not using well-known forms of insurance, such as Direct Primary Care, or who are not seeking traditional medical care are not represented."
  },
  {
    "objectID": "capstone.html#introduction-1",
    "href": "capstone.html#introduction-1",
    "title": "Preventative Care in the United States",
    "section": "5.1 Introduction",
    "text": "5.1 Introduction\nIn order to evaluate the health status of a group of people, we turned to three common metrics for doing so: life expectancy, mortality, and infant mortality.³ In the following sections, we modeled each of these by a list of variables representing access to care (see Section 8.1.2). Our goal was to determine how access to care influenced each of these three metrics for determining health of a population."
  },
  {
    "objectID": "capstone.html#goal-1-analyzing-impact-of-access-to-care-on-health-metrics",
    "href": "capstone.html#goal-1-analyzing-impact-of-access-to-care-on-health-metrics",
    "title": "Preventative Care in the United States",
    "section": "5.2 Goal 1: Analyzing Impact of Access to Care on Health Metrics",
    "text": "5.2 Goal 1: Analyzing Impact of Access to Care on Health Metrics\n\n5.2.1 Life Expectancy\n\n\n\nFig 2A: Median life expectancy of most states is between 77 and 80 years old.\n\n\nFigure 2A demonstrates how median life expectancy varies by state. We decided to keep state in our linear model because it did have a significant correlation with life expectancy. Since not all of the states were significantly correlated, we created the following plot to show which states were significantly correlated (positively or negatively) with life expectancy, as is seen in Figure 2B.\n\n\n\nFigure 2B: There does not appear to be a geographic influence on median life expectancy.\n\n\nFigure 2C shows our linear model for preventative healthcare measures and life expectancy. We found that Primary Care Physician (PCP) Rate and Ratio were both positively correlated with life expectancy. Percentage of Food Insecurity was negatively correlated with life expectancy (that is, as food insecurity increased, life expectancy decreased). Percentage of Access to Broadband Internet was also positively correlated with life expectancy.\nThese were all expected, but what was surprising was that the Residential Segregation Index was positively correlated with life expectancy but the opposite relationship was found for the Segregation Index. While we expected to see Segregation Index negatively correlated with life expectancy, it seems to be paradoxical that the opposite was true for the Residential Segregation Index. We realized that our Residential Segregation Index had a lot of missing values, so plotting it against life expectancy didn’t reveal any visible trend. To improve this model in the future, we would remove this predictor.\n\n\n\nFigure 2C: Life Expectancy Linear Model Coefficients.\n\n\nTo better understand the survival (life expectancy) of different groups for each of these variables, we created Kaplan-Meier (KM) Curves where we plotted each variable by quartile. We then conducted a log rank test to compare across quantiles to see if the groups were significantly different from each other. Figure 2D shows life expectancy based on the percentage of food insecurity. Figure 2E shows the results of the log rank test (which are significant as p = &lt;2e-16). Quantiles 1 and 2 (less food insecurity) observed less death than expected, but quantiles 3 and 4 (more food insecurity) observed more death than expected. This demonstrates that we are seeing a significant difference between life expectancy of people in the lower versus the higher quantiles of food insecurity.\n\n\n\nFigure 2D: As expected, those who are more food insecure have lower life expectancies.\n\n\n\n\n\nFigure 2E: Log Rank Test Results for Life Expectancy and Percentage of Food Insecurity.\n\n\nKaplan-Meier Curves for life expectancy were made with the following variables: PCP Rate and Ratio, Percentage of Food Insecurity, Segregation Index, and Percentage of Broadband Internet Access. Log rank tests were performed, and all of the results were significant. To explore the curves and log rank test results, please explore our gallery below:\nadd a gallery here?\nWe then used machine learning algorithms to predict life expectancy of individuals based on these significant covariates along with the top ten features found through KBest (see Supplemental Figure 1A). It is important to note that a lot of features were found in both the linear regression model explained above and in the KBest result.\nOur model predicted life expectancy based only on the fifteen significant access-to-care-related variables with 56% accuracy. While this may at first appear unimpressive, it’s important to note that 56% of life expectancy can be predicted or explained by only fifteen items- all of which relate to one’s access to healthcare. Only the remaining 44% can be explained by all other factors in a person’s life.\n\n\n5.2.2 Infant Mortality\n\n\n\nFigure 3A: Most states see an infant mortaliy rate of 6 deaths per 1,000 live births.\n\n\nFigure 3A shows a difference between median infant mortality rates between states. Note that the chart appears to “stair-step” as Infant Mortality Rate are represented as integers rather than continuous numbers. Because of the linear trend associated with each state, we included the variable in our linear model to determine which states were significantly correlated with infant mortality.\n\n\n\nFigure 3B: Many of the same states that have longer life expectancies (Fig. 2B) as have lower infant mortality rates. Only Mississippi and Maryland have infant mortality rates significantly greater than the rest.\n\n\nFigure 3B shows which states were positively or negatively correlated with infant mortality. Note this map has negative significance in green since that would mean less infant mortality. In this case, Maryland and Mississippi have significantly higher rates of infant mortality.\nIn terms of preventative healthcare measures that were significantly correlated with infant mortality (Figure 3C), we found that Median Household Income and Broadband Internet Access were significantly correlated in the negative direction with infant mortality. That is, as income and access to the Internet increased, infant mortality rates decreased. We came across the same issue with segregation here as we did in our life expectancy model. The Segregation Index coefficient shows that as segregation increases, infant mortality rates increase as well.\n\n\n\nFigure 3C: Infant Mortality Linear Model Coefficients.\n\n\nIn our machine learning model, we repeated the same process for infant mortality rate as for life expectancy, but got a low accuracy score of 36% due to the high number of NAs in our Infant Mortality Rate column. Future analyses would do well to increase record-keeping of infant mortality rates by county as the metric “indicates the current health status of a population and reflects the overall state of maternal health, as well as the quality and accessibility of primary health care available to pregnant women and infants.”³\n\n\n5.2.3 Age Adjusted Death Rate\n\n\n\nFigure 4A: Most states have a median ade-adjusted mortality rate of 300-400 deaths per 100,000 people. Mississippi has both the highest median age-adjusted mortality and infant mortality rates (Fig. 3A).\n\n\nAge-adjusted death rate (mortality rate) appeared to vary across states as seen in Figure 4A, so we again kept state in our linear model. Figure 4B shows which states were significantly correlated with mortality rate. Negative correlation is in green (AZ) showing a significantly lower death rate in Arizona. Positive correlation is in red, showing significantly higher death rates.\n\n\n\nFigure 4B: Most states do not have an age-adjusted mortality rate different from the rest. Arizona is the only state with a significantly lower rate than the other forty-nine.\n\n\nPreventative healthcare measures that were significantly correlated with mortality rate are shown in figure 4C. As food insecurity, segregation (excluding residential segregation), and school segregation increased, mortality rates increased as well. As broadband internet access, vaccination, and number of rural residents increased, mortality rates decreased.\nLooking at demographics, we noticed as income increased among white Americans, mortality rates decreased. This income trend was the opposite among Asian and Hispanic Americans. Looking closer at the income correlation plots, the trends for Asian and Hispanic Americans appear to have more data points that could be considered outliers. As the percentage of severe housing issues increased, the mortality rate decreased, but the correlation plot appears to have outliers that could be skewing this trend as well.\n\n\n\nFigure 4C: Age Adjusted Death Rate (Mortality Rate) Linear Model Coefficients.\n\n\nFinally, we repeated our machine learning process to predict age-adjusted death rate based on our significant access to care covariates. Our model accurately predicted the binned death rate for 62% of our test data. Just thirteen access-to-care-related covariates predicted mortality rate 62% of the time! This again emphasizes the importance of access to care in one’s overall health status."
  },
  {
    "objectID": "capstone.html#goal-2-predicting-chronic-conditions-based-on-insurance-type",
    "href": "capstone.html#goal-2-predicting-chronic-conditions-based-on-insurance-type",
    "title": "Preventative Care in the United States",
    "section": "5.3 Goal 2: Predicting Chronic Conditions Based On Insurance Type",
    "text": "5.3 Goal 2: Predicting Chronic Conditions Based On Insurance Type\nTo answer the question of how state insurance in particular impacts one’s health status, we evaluated two common chronic conditions in the United States, diabetes and cardiovascular disease.\n\n5.3.1 Diabetes\nWe immediately plotted our mean diabetes percentages by Medicaid percentage across states to see if any obvious correlation existed (see Figure 5B). No correlation was obvious, but there appeared to be a slight linear trend. We created a linear regression model predicting diabetes prevalence by many Medicaid-related covariates, such as how many adults did not see a doctor in the past twelve months due to cost, state Medicaid expenditure, state Medicaid spending, total Medicaid spending, and population percentage on Medicaid. Our simple model showed a surprising 38% accuracy in predicting how many people in a given population would have diabetes based on these factors. While Medicaid-related factors may not be able to completely predict diabetes prevalence, it certainly plays a role.\n\n\n\nFigure 5A: There may be a slight linear correlation between mean diabetes percentage per state and Medicaid percentage. There may be 2-3 clusters- analysis will show us if these trends exist!\n\n\n\n\n5.3.2 Cardiovascular Disease (CVD)\nAs with our diabetes dataset, we again repeated the above process to predict CVD prevalence based on Medicaid-only related factors. Our simple scatterplot shows a faint linear trend and two potential clusters. Shockingly, our model accurately predicted CVD prevalence 46% of the time! This is such a high number that it cannot be ignored, and we can assume Medicaid plays some factor in a population’s cardiovascular disease prevalence.\n\n\n\nFigure 5B: As with Fig 5A, there again appears to be a slight linear correlation between mean CVD percentage per state and Medicaid percentage, and 2 possible clusters. Further analysis to revealed if these trends existed."
  },
  {
    "objectID": "capstone.html#goal-3-creating-an-overall-health-quality-variable",
    "href": "capstone.html#goal-3-creating-an-overall-health-quality-variable",
    "title": "Preventative Care in the United States",
    "section": "5.4 Goal 3: Creating an Overall Health Quality Variable",
    "text": "5.4 Goal 3: Creating an Overall Health Quality Variable\nAs a final metric for assessing quality of health, we wanted to create a new variable that represented the overall health of a population. We knew that the following variables should be included in the creation of this new variable: Life Expectancy, Age-Adjusted Death Rate, Years of Potential Life Lost Rate, Percent of Frequent Physical Distress Days, and Percent of Frequent Mental Distress Days. We chose the first three for the same reasons explained in the introduction to our results.3 Note that we left out Infant Mortality Rate due to its high number of NAs, as explained above. We added the final two metrics to account for a person’s perceived quality of life, which does influence’s one’s actual health quality. A clear linear relationship is seen between each of these metrics in the pair plot below (Fig 6A).\n\n\n\nFigure 6A: We chose these five variables to summarize our overall health metric since they are all linearly correlated with each other.\n\n\nThough the first eigenvalue of our entire dataset only explained 31% of the variance in our dataset, we continued by projecting the variables above to this first eigenvalue, thus “creating” a new variable that represents overall health. We then plotted the weights of all of our other variables against this new one to see how much each contributed to overall health. 87 of our original features contributed negatively to this new variable and 35 positively. Fig6B shows which features contribute the most in both a positive and negative direction to health.\n\n\n\nFigure 6B: Number of alcohol associated deaths, internet access, education level, number of dentists, and uninsured status are all variables that contribute most heavily to our overall health metric."
  },
  {
    "objectID": "capstone.html#supplemental-tables",
    "href": "capstone.html#supplemental-tables",
    "title": "Preventative Care in the United States",
    "section": "8.1 Supplemental Tables",
    "text": "8.1 Supplemental Tables\n\n8.1.1 S.Table 1: CSV containing all variables used to assess weight contribution to new variable\n\n Download S.Table 1B\n\n\n\n\n8.1.2 S.Table 2: CSV containing all variables used to assess access to care\n\n Download S.Table 1A"
  },
  {
    "objectID": "capstone.html#supplemental-figures",
    "href": "capstone.html#supplemental-figures",
    "title": "Preventative Care in the United States",
    "section": "8.2 Supplemental Figures",
    "text": "8.2 Supplemental Figures\n\n\n\nFigure S.1A: Mean household income, food insecurity, and income all contribute the most to life expectancy.\n\n\n\n\n\nFigure S.1B: Different metrics of wealth or poverty impact infant mortality rate.\n\n\n\n\n\nFigure S.1C: Which state you live in, food insecurity, and income-related factors contribute the most to age-adjusted mortality rate.\n\n\n\n\n\nFigure S.1D: We binned our life expectancy data by quartiles (after removing outliers) to ensure balanced weights given to each class.\n\n\n\n\n\nFigure S.1E: With balanced weights, our life expectancy model did a fairly good job at predicting life expectancy and did not appear to favor one group over another.\n\n\n\n\n\nS.Figure S.1F: As with our life expectancy model, binning our age-adjusted mortality rates allowed our model to balance both accuracy and fairness by not favoring one group over another.\n\n\n\n\n\nFigure S.1G: It takes about 25 components to explain 90% of the variance seen in our life expectancy model\n\n\n\n\n\nFigure S.1H: It takes about 20 components to explain 90% of the variance seen in our infant mortality rate model.\n\n\n\n\n\nFigure S.1I: It takes about 25 components to explain 90% of the variance seen in our age-adjusted death rate model.\n\n\n\n\n\nFigure S.1J: Our engineered overall health variable (made from just five features) represents about 31% of the variance seen in our entire dataset."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "United States’ Health Quality",
    "section": "",
    "text": "To answer questions regarding the effectiveness of preventative care, we investigated current relationships between health care, access to care, insurance type, and overall health outcomes across the United States. To do so, we took a multi-layered approach to our data:\n\nCompare how access to care impacts common health metrics such as life expectancy, mortality, and infant mortality.³\nInvestigate predictability of chronic condition prevalence between public and private insurances.\nEngineer a variable that encapsulates all health metrics to discover what factors are most important to health overall.\n\nBy examining these questions, we aimed to contribute to the understanding of how preventative care can improve public health in the United States."
  },
  {
    "objectID": "index.html#data-ingestion",
    "href": "index.html#data-ingestion",
    "title": "United States’ Health Quality",
    "section": "3.1 Data Ingestion",
    "text": "3.1 Data Ingestion\nWe gathered data from two sources: KFF (an independent source for health policy research, polling, and news)⁷ and County Health Rankings and Roadmaps (CHRR).² Though we collected data across several years, we analyzed only data from 2022 due to data quality concerns when comparing year to year.\n\n3.1.1 KFF: Collection and Cleaning\nWe generated a custom report from data available on KFF, downloading a large variety of data from 2017-2022 (not including 2020 due to lack of data collection) for each state in the U.S. Variables we investigated from this dataset included percentage of population on Medicare, percentage of adults who smoke, healthcare expenditure, median annual household income, cervical cancer incidence rate, and many more potentially relevant factors.⁷\nKFF data for each state was downloaded as CSVs. We chose the most recent dates for all of the different health and insurance related questions between 2017-2022. The CSVs originally had a question, state, and value field. We used text parsing to create a column called demographic and a column called group. This allowed us to parse out demographics like age, race/ethnicity, poverty level and create groups within each of those.\nWe also created fields called year and measure, and parsed out the years and measurements from the question field. Some questions had multiple demographics, so we created a secondary_demographic field and a secondary_group field. These are not ranked.\nFinally, we added a county column (which we filled with all NA) and edited the state and question fields to replicate the way that data from our CHFF dataset was formatted. This allowed us to merge the two datasets.\n\n\n3.1.2 CHRR: Collection and Cleaning\nSimilar to KFF, we downloaded data for each state from 2017-2022 (not including 2020 due to lack of data collection) from County Health Rankings and Roadmaps (CHRR). We chose the “20xx County Health Release National Data” links for each year. Data from CHRR originally came in two separate CSVs for each year and broke up the data by each county in the United States. This data included metrics such as life_expectancy, age-adjusted_death_rate, years_of_potential_life_loss_rate, food_environment_index, percentage_of_physically_inactive_adults, percentage_of_excessive_drinking, Primary_Care_Provider_ratio, and much more.²\nFirst, we cleaned up the columns. We reviewed the documentation and renamed any potentially confusing column names. For example, #_Medicaid_Enrollees became no_female_medicaid_enrollees to avoid mistakenly believing the first column included both genders in its count. We dropped columns that would not be of help to us, such as columns containing the word Unreliable. We replaced all spaces with an underscore.\nSecond, we joined the two CSVs for each year to have one CSV per year and added a Year column to help with merging later.\nFinally, we reformatted the CSVs to match that of the KFF data, where our original columns became the question column and the values filled in a new values column. Again, we used text parsing such as grepl and gsub to fill in our newly created demographic, measure, group, secondary_demographic, and secondary_group, columns. For example, if our question was mean_%_Children_in_Poverty_(white), our demographic, group, secondary_demographic, and secondary_group columns became “Race/Ethnicity”, “White”, “Age”, and “0-17”, respectively.\nSince the questions and potential answers collected by CHRR data varied each year, we made sure that our cleaning code was modified for each year to both accommodate the changes in the data and match identical answers from previous years. As an example, the only races that were listed as options in the 2017 data were “White”, “Black”, “Hispanic”, and “Asian”. However, by the 2022 data collection, the options had expanded to include “American Indian/Alaskan Native”, “Native Hawaiian/Other Pacific Islander”, and “Other/Multiple Races.” In 2022, “Black” was changed to “African American,” so we changed it back to “Black” to both match the earlier CHRR data and the KFF data."
  },
  {
    "objectID": "index.html#data-organization",
    "href": "index.html#data-organization",
    "title": "United States’ Health Quality",
    "section": "3.2 Data Organization",
    "text": "3.2 Data Organization\nData was combined and normalized to third normal form. The ids were primary keys for each table except for question_responses, where state_id, year_id, and question_id were used as a compound primary key. We used the same foreign key for group and secondary_group and another separate foreign key for both type and secondary_type. All columns had a NOT NULL constraint except for unit_type from the unit table, and unit_id, secondary_group_id, and secondary_type_id from question_responses.\n\n\n\nFigure 1: ERD."
  },
  {
    "objectID": "index.html#data-analysis",
    "href": "index.html#data-analysis",
    "title": "United States’ Health Quality",
    "section": "4.1 Data Analysis",
    "text": "4.1 Data Analysis\n\n4.1.1 Statistical Thinking\nWe determined health status using commonly used proxies such as life expectancy and mortality rates.³ We used statistics (log rank tests) and modeling (Kaplan-Meier curves and linear regression) to determine how access to preventative care correlates with health status. We compared proportions across states to account for differences in population.\nIn our linear models created in R, we first took the natural logarithm of income-related data due to both its skewed distribution and disproportionate scale (in comparison to the rest of our data).\n\n\n\n\n\n\nWhat are these statistical tests?\n\n\n\n\n\n\n\n\n\n\n\n\nTest\nDescription\n\n\n\n\nKaplan-Meier Curve\nA Kaplan-Meier (KM) curve is a display of survival data over time and across groups.\n\n\nLog Rank Test\nA log rank test is used to determine if the groups in a KM curve are significant.\n\n\nLinear Regression\nLinear regression is a statistical test used to find and quanitfy linear trends between data.\n\n\n\n\n\n\n\n\n4.1.2 Data Visualization\nWe used data visualization as part of both our exploratory data analysis and in our final outcome. We created maps of the United States to determine if there is a spatial relationship between our variables and quality of health. Various other visualizations were displayed from our statistical analysis and machine learning product, such as Kaplan-Meier curves, graphs of K-Best’s top features, confusion matrices, and K-Means and/or Gaussian Mixture Model scatterplots, where appropriate.\n\n\n4.1.3 Data Engineering\nWe stored our data into a relational database and accessed it with Postgresql (through Railway). We accessed our data in both R and Python using the RPostgreSQL and sqlalchemy libraries, respectively. A detailed description for how this was done is in the data section above.\n\n\n4.1.4 Machine Learning\nWe used machine learning models such as ensembles, logistic regression, random forest, naive bayes, PCA, KMeans, Gaussian Mixture Models, and more to explore relationships and predict health outcomes from our data. For example, we predicted metrics like life expectancy based on our access to care variables. We also predicted the prevalence of common chronic conditions, such as Diabetes, within each state based on the percentage of people on Medicaid. Finally, we created a new variable that represented overall health quality.\n\n4.1.4.1 Process outlines:\n\nGoal 1Goal 2Goal 3\n\n\nPredicting health by access to care\n\nUse KMeans to find the top 10 features from each model. Combine these variables with significant variables from the linear regression models completed in R.\nCreate our desired dataframe by reading in data from our remote database and joining where necessary.\nPreprocess:\n\nDrop NAs while optimizing data frame size via trial and error.\nUse StandardScaler and OneHotEncoder tools from sklearn to transform our numeric and categorical data, respectively.\n\nUse KMeans to find the top 10 features from each model. (See Supplemental Figures 1A, 1B, and 1C). Combine these variables with significant variables from the linear regression models completed in R.\nContinue preprocessing with the reduced dataset (using only variables from step 3)\n\nBin and modify data as necessary. This ensured equal representation across classes for each predicted y variable. A. In order to use classification tools such as RandomForestClassifier or GradientBoostingClassifier, we binned all our data by quartiles before running it through our models. B. For life expectancy, we dropped outliers first (ages below 60 and above 90, see Supplemental Figure 1D).\nTrain/test split dataset\n\nCreate model\n\nUse LogisticRegression, RandomForestClassifier, GradientBoostingClassifier, CategoricalNaiveBayes, and Ensemble. Find which model performs the best.\nHyperparameterize the model that works best from step 5i.\nCross validate finalized model\nTest on testing data to find true accuracy\nConfusion matrix to see what went wrong (see Supplemental Figures 1E and 1F).\n\nAdd PCA to the model\n\nDetermine how many components explain 90% variance in the model (see Supplemental Figures 1G, 1H, and 1I).\nAdd PCA with that number of components to the optimized pipeline made from Step 5.\n\n\n\n\nPredicting disease prevalence by insurance type\n\nManipulate data to find mean prevalence of the disease by state. Use this state-wide data rather than the county data as the Medicaid covariates were only available by state.\nPreprocess, split, and model the data as outlined in the first process.\n\n\n\nEngineering overall health variable\n\nGather our entire dataset (not just access to care related variables) See Section 8.1.1 for a list of all variables used.\nPreprocess the dataset using StandardScaler and OneHotEncoder to the appropriate columns.\nUse PCA to see how much variance can be explained by the first eigenvalue (see Supplemental Figure 1J).\nProject desired health variables to the first eigenvalue.\nCompare weights of all variables to see how much they each contribute to this “new variable.”\n\n\n\n\n\n\n\n\n\n\nWhat are these models and tools?\n\n\n\n\n\n\n4.1.5 Model Optimization Tools\n\n\n\n\n\n\n\nName\nExplaination\n\n\n\n\nK-Best Feature Selection\nK-Best feature selection is a tool used in machine learning used to find which variables in a given model most contribute to its prediction accuracy.\n\n\nConfusion Matrices\nConfusion matrices are plots of the true and predicted values of a given model and are used to determine where a model is succeeding and/or failing.\n\n\n\n\n\n4.1.6 Data Preprocessing Tools\n\n\n\n\n\n\n\nName\nExplaination\n\n\n\n\nStandard Scaler\nStandard Scaler is a tool you can use in machine learning to standardize all numeric inputs so the model can correctly assess the impact of each value.\n\n\nOne Hot Encoder\nSimilar to Standard Scaler, One Hot Encoder is a method use to convert character data to numeric in a standardized way so the model can weigh the impact of character input along with numeric.\n\n\n\n\n\n4.1.7 Supervised Classification Models\n\n\n\n\n\n\n\nName\nExplaination\n\n\n\n\nRandom Forests\nRandom Forests randomly distribute the data given to it into multiple “trees” and averages the outcome from each tree to come to its final result.\n\n\nNaive Bayes\nNaive Bayes uses probability to find the most likely outcome.\n\n\nLogistic Regression\nLogisitic regression finds the linear regression of the log odds of the predictor variables to predict a binary outcome.\n\n\nGradient Boosting\nRather than creating lots of uncorrelated models like Random Forest, Gradient Boosting fits many models where each successive one corrects upon where the previous one was wrong.\n\n\nEnsemble\nEnsemble models combine many user-specified models and comes to its final outcome by averaging the individual outcomes of each model made up within it.\n\n\n\n\n\n4.1.8 Unsupervised Dimension Reduction Model\n\n\n\n\n\n\n\nName\nExplaination\n\n\n\n\nPCA\nPrinciple Component Analysis (PCA) is a method of reducing the number of variables in a model by combining them into the principle components that describe the most variance in a given dataset.\n\n\n\n\n\n4.1.9 Unsupervised Clustering Models\n\n\n\n\n\n\n\nName\nExplaination\n\n\n\n\nK-Means\nK-Means is a clustering method that attempts to divide up the data into a specified number of groups based on how close each data point is to each other.\n\n\nGaussian Mixture Model\nGaussian Mixture Model is another clustering method that assumes a specificed number of normally distributed clusters and assigns data points to the normal curve they best fit.\n\n\n\n\n\n\n\n\n\n\n4.1.10 Data Ethics\nWe were wary of furthering the gap between classes, races, and/or genders. Often, those in lower socioeconomic status tend to have lower quality of health and less access to affordable healthcare. Our goal was not to perpetuate this gap but to find potential solutions for these underserved populations. We also recognized that our datasets were incomplete and that we were not be able to represent everyone’s needs. Those who are not using well-known forms of insurance, such as Direct Primary Care, or who are not seeking traditional medical care are not represented."
  },
  {
    "objectID": "index.html#introduction-1",
    "href": "index.html#introduction-1",
    "title": "United States’ Health Quality",
    "section": "5.1 Introduction",
    "text": "5.1 Introduction\nIn order to evaluate the health status of a group of people, we turned to three common metrics for doing so: life expectancy, mortality, and infant mortality.³ In the following sections, we modeled each of these by a list of variables representing access to care (see Section 8.1.2). Our goal was to determine how access to care influenced each of these three metrics for determining health of a population."
  },
  {
    "objectID": "index.html#goal-1-analyzing-impact-of-access-to-care-on-health-metrics",
    "href": "index.html#goal-1-analyzing-impact-of-access-to-care-on-health-metrics",
    "title": "United States’ Health Quality",
    "section": "5.2 Goal 1: Analyzing Impact of Access to Care on Health Metrics",
    "text": "5.2 Goal 1: Analyzing Impact of Access to Care on Health Metrics\n\n5.2.1 Life Expectancy\n\n\n\nFig 2A: Median life expectancy of most states is between 77 and 80 years old.\n\n\nFigure 2A demonstrates how median life expectancy varies by state. We decided to keep state in our linear model because it did have a significant correlation with life expectancy. Since not all of the states were significantly correlated, we created the following plot to show which states were significantly correlated (positively or negatively) with life expectancy, as is seen in Figure 2B.\n\n\n\nFigure 2B: There does not appear to be a geographic influence on median life expectancy.\n\n\nFigure 2C shows our linear model for preventative healthcare measures and life expectancy. We found that Primary Care Physician (PCP) Rate and Ratio were both positively correlated with life expectancy. Percentage of Food Insecurity was negatively correlated with life expectancy (that is, as food insecurity increased, life expectancy decreased). Percentage of Access to Broadband Internet was also positively correlated with life expectancy.\nThese were all expected, but what was surprising was that the Residential Segregation Index was positively correlated with life expectancy but the opposite relationship was found for the Segregation Index. While we expected to see Segregation Index negatively correlated with life expectancy, it seems to be paradoxical that the opposite was true for the Residential Segregation Index. We realized that our Residential Segregation Index had a lot of missing values, so plotting it against life expectancy didn’t reveal any visible trend. To improve this model in the future, we would remove this predictor.\n\n\n\nFigure 2C: Life Expectancy Linear Model Coefficients.\n\n\nTo better understand the survival (life expectancy) of different groups for each of these variables, we created Kaplan-Meier (KM) Curves where we plotted each variable by quartile. We then conducted a log rank test to compare across quantiles to see if the groups were significantly different from each other. Figure 2D shows life expectancy based on the percentage of food insecurity. Figure 2E shows the results of the log rank test (which are significant as p = &lt;2e-16). Quantiles 1 and 2 (less food insecurity) observed less death than expected, but quantiles 3 and 4 (more food insecurity) observed more death than expected. This demonstrates that we are seeing a significant difference between life expectancy of people in the lower versus the higher quantiles of food insecurity.\n\n\n\nFigure 2D: As expected, those who are more food insecure have lower life expectancies.\n\n\n\n\n\nFigure 2E: Log Rank Test Results for Life Expectancy and Percentage of Food Insecurity.\n\n\nKaplan-Meier Curves for life expectancy were made with the following variables: PCP Rate and Ratio, Percentage of Food Insecurity, Segregation Index, and Percentage of Broadband Internet Access. Log rank tests were performed, and all of the results were significant. To explore the curves and log rank test results, please explore our gallery below:\nadd a gallery here?\nWe then used machine learning algorithms to predict life expectancy of individuals based on these significant covariates along with the top ten features found through KBest (see Supplemental Figure 1A). It is important to note that a lot of features were found in both the linear regression model explained above and in the KBest result.\nOur model predicted life expectancy based only on the fifteen significant access-to-care-related variables with 56% accuracy. While this may at first appear unimpressive, it’s important to note that 56% of life expectancy can be predicted or explained by only fifteen items- all of which relate to one’s access to healthcare. Only the remaining 44% can be explained by all other factors in a person’s life.\n\n\n5.2.2 Infant Mortality\n\n\n\nFigure 3A: Most states see an infant mortaliy rate of 6 deaths per 1,000 live births.\n\n\nFigure 3A shows a difference between median infant mortality rates between states. Note that the chart appears to “stair-step” as Infant Mortality Rate are represented as integers rather than continuous numbers. Because of the linear trend associated with each state, we included the variable in our linear model to determine which states were significantly correlated with infant mortality.\n\n\n\nFigure 3B: Many of the same states that have longer life expectancies (Fig. 2B) as have lower infant mortality rates. Only Mississippi and Maryland have infant mortality rates significantly greater than the rest.\n\n\nFigure 3B shows which states were positively or negatively correlated with infant mortality. Note this map has negative significance in green since that would mean less infant mortality. In this case, Maryland and Mississippi have significantly higher rates of infant mortality.\nIn terms of preventative healthcare measures that were significantly correlated with infant mortality (Figure 3C), we found that Median Household Income and Broadband Internet Access were significantly correlated in the negative direction with infant mortality. That is, as income and access to the Internet increased, infant mortality rates decreased. We came across the same issue with segregation here as we did in our life expectancy model. The Segregation Index coefficient shows that as segregation increases, infant mortality rates increase as well.\n\n\n\nFigure 3C: Infant Mortality Linear Model Coefficients.\n\n\nIn our machine learning model, we repeated the same process for infant mortality rate as for life expectancy, but got a low accuracy score of 36% due to the high number of NAs in our Infant Mortality Rate column. Future analyses would do well to increase record-keeping of infant mortality rates by county as the metric “indicates the current health status of a population and reflects the overall state of maternal health, as well as the quality and accessibility of primary health care available to pregnant women and infants.”³\n\n\n5.2.3 Age Adjusted Death Rate\n\n\n\nFigure 4A: Most states have a median ade-adjusted mortality rate of 300-400 deaths per 100,000 people. Mississippi has both the highest median age-adjusted mortality and infant mortality rates (Fig. 3A).\n\n\nAge-adjusted death rate (mortality rate) appeared to vary across states as seen in Figure 4A, so we again kept state in our linear model. Figure 4B shows which states were significantly correlated with mortality rate. Negative correlation is in green (AZ) showing a significantly lower death rate in Arizona. Positive correlation is in red, showing significantly higher death rates.\n\n\n\nFigure 4B: Most states do not have an age-adjusted mortality rate different from the rest. Arizona is the only state with a significantly lower rate than the other forty-nine.\n\n\nPreventative healthcare measures that were significantly correlated with mortality rate are shown in figure 4C. As food insecurity, segregation (excluding residential segregation), and school segregation increased, mortality rates increased as well. As broadband internet access, vaccination, and number of rural residents increased, mortality rates decreased.\nLooking at demographics, we noticed as income increased among white Americans, mortality rates decreased. This income trend was the opposite among Asian and Hispanic Americans. Looking closer at the income correlation plots, the trends for Asian and Hispanic Americans appear to have more data points that could be considered outliers. As the percentage of severe housing issues increased, the mortality rate decreased, but the correlation plot appears to have outliers that could be skewing this trend as well.\n\n\n\nFigure 4C: Age Adjusted Death Rate (Mortality Rate) Linear Model Coefficients.\n\n\nFinally, we repeated our machine learning process to predict age-adjusted death rate based on our significant access to care covariates. Our model accurately predicted the binned death rate for 62% of our test data. Just thirteen access-to-care-related covariates predicted mortality rate 62% of the time! This again emphasizes the importance of access to care in one’s overall health status."
  },
  {
    "objectID": "index.html#goal-2-predicting-chronic-conditions-based-on-insurance-type",
    "href": "index.html#goal-2-predicting-chronic-conditions-based-on-insurance-type",
    "title": "United States’ Health Quality",
    "section": "5.3 Goal 2: Predicting Chronic Conditions Based On Insurance Type",
    "text": "5.3 Goal 2: Predicting Chronic Conditions Based On Insurance Type\nTo answer the question of how state insurance in particular impacts one’s health status, we evaluated two common chronic conditions in the United States, diabetes and cardiovascular disease.\n\n5.3.1 Diabetes\nWe immediately plotted our mean diabetes percentages by Medicaid percentage across states to see if any obvious correlation existed (see Figure 5B). No correlation was obvious, but there appeared to be a slight linear trend. We created a linear regression model predicting diabetes prevalence by many Medicaid-related covariates, such as how many adults did not see a doctor in the past twelve months due to cost, state Medicaid expenditure, state Medicaid spending, total Medicaid spending, and population percentage on Medicaid. Our simple model showed a surprising 38% accuracy in predicting how many people in a given population would have diabetes based on these factors. While Medicaid-related factors may not be able to completely predict diabetes prevalence, it certainly plays a role.\n\n\n\nFigure 5A: There may be a slight linear correlation between mean diabetes percentage per state and Medicaid percentage. There may be 2-3 clusters- analysis will show us if these trends exist!\n\n\n\n\n5.3.2 Cardiovascular Disease (CVD)\nAs with our diabetes dataset, we again repeated the above process to predict CVD prevalence based on Medicaid-only related factors. Our simple scatterplot shows a faint linear trend and two potential clusters. Shockingly, our model accurately predicted CVD prevalence 46% of the time! This is such a high number that it cannot be ignored, and we can assume Medicaid plays some factor in a population’s cardiovascular disease prevalence.\n\n\n\nFigure 5B: As with Fig 5A, there again appears to be a slight linear correlation between mean CVD percentage per state and Medicaid percentage, and 2 possible clusters. Further analysis to revealed if these trends existed."
  },
  {
    "objectID": "index.html#goal-3-creating-an-overall-health-quality-variable",
    "href": "index.html#goal-3-creating-an-overall-health-quality-variable",
    "title": "United States’ Health Quality",
    "section": "5.4 Goal 3: Creating an Overall Health Quality Variable",
    "text": "5.4 Goal 3: Creating an Overall Health Quality Variable\nAs a final metric for assessing quality of health, we wanted to create a new variable that represented the overall health of a population. We knew that the following variables should be included in the creation of this new variable: Life Expectancy, Age-Adjusted Death Rate, Years of Potential Life Lost Rate, Percent of Frequent Physical Distress Days, and Percent of Frequent Mental Distress Days. We chose the first three for the same reasons explained in the introduction to our results.3 Note that we left out Infant Mortality Rate due to its high number of NAs, as explained above. We added the final two metrics to account for a person’s perceived quality of life, which does influence’s one’s actual health quality. A clear linear relationship is seen between each of these metrics in the pair plot below (Fig 6A).\n\n\n\nFigure 6A: We chose these five variables to summarize our overall health metric since they are all linearly correlated with each other.\n\n\nThough the first eigenvalue of our entire dataset only explained 31% of the variance in our dataset, we continued by projecting the variables above to this first eigenvalue, thus “creating” a new variable that represents overall health. We then plotted the weights of all of our other variables against this new one to see how much each contributed to overall health. 87 of our original features contributed negatively to this new variable and 35 positively. Fig6B shows which features contribute the most in both a positive and negative direction to health.\n\n\n\nFigure 6B: Number of alcohol associated deaths, internet access, education level, number of dentists, and uninsured status are all variables that contribute most heavily to our overall health metric."
  },
  {
    "objectID": "index.html#supplemental-tables",
    "href": "index.html#supplemental-tables",
    "title": "United States’ Health Quality",
    "section": "8.1 Supplemental Tables",
    "text": "8.1 Supplemental Tables\n\n8.1.1 S.Table 1: CSV containing all variables used to assess weight contribution to new variable\n\n Download S.Table 1B\n\n\n\n\n8.1.2 S.Table 2: CSV containing all variables used to assess access to care\n\n Download S.Table 1A"
  },
  {
    "objectID": "index.html#supplemental-figures",
    "href": "index.html#supplemental-figures",
    "title": "United States’ Health Quality",
    "section": "8.2 Supplemental Figures",
    "text": "8.2 Supplemental Figures\n\n\n\nFigure S.1A: Mean household income, food insecurity, and income all contribute the most to life expectancy.\n\n\n\n\n\nFigure S.1B: Different metrics of wealth or poverty impact infant mortality rate.\n\n\n\n\n\nFigure S.1C: Which state you live in, food insecurity, and income-related factors contribute the most to age-adjusted mortality rate.\n\n\n\n\n\nFigure S.1D: We binned our life expectancy data by quartiles (after removing outliers) to ensure balanced weights given to each class.\n\n\n\n\n\nFigure S.1E: With balanced weights, our life expectancy model did a fairly good job at predicting life expectancy and did not appear to favor one group over another.\n\n\n\n\n\nS.Figure S.1F: As with our life expectancy model, binning our age-adjusted mortality rates allowed our model to balance both accuracy and fairness by not favoring one group over another.\n\n\n\n\n\nFigure S.1G: It takes about 25 components to explain 90% of the variance seen in our life expectancy model\n\n\n\n\n\nFigure S.1H: It takes about 20 components to explain 90% of the variance seen in our infant mortality rate model.\n\n\n\n\n\nFigure S.1I: It takes about 25 components to explain 90% of the variance seen in our age-adjusted death rate model.\n\n\n\n\n\nFigure S.1J: Our engineered overall health variable (made from just five features) represents about 31% of the variance seen in our entire dataset."
  }
]